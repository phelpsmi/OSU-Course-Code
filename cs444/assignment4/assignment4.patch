--- orig-slob.c	2016-11-26 15:32:58.005836000 -0800
+++ slob.c	2016-11-28 11:11:55.061349000 -0800
@@ -67,6 +67,8 @@
 #include <linux/rcupdate.h>
 #include <linux/list.h>
 #include <linux/kmemleak.h>
+#include <linux/linkage.h>
+#include <linux/syscalls.h>
 
 #include <trace/events/kmem.h>
 
@@ -92,6 +94,22 @@
 };
 typedef struct slob_block slob_t;
 
+#define SET_FREE_SPACE() { \
+	free_space = 0;\
+	slob_list = &free_slob_small;\
+	list_for_each_entry(sp, slob_list, list){\
+		free_space += sp->units;\
+	}\
+	slob_list = &free_slob_medium;\
+	list_for_each_entry(sp, slob_list, list){\
+		free_space += sp->units;\
+	}\
+	slob_list = &free_slob_large;\
+	list_for_each_entry(sp, slob_list, list){\
+		free_space += sp->units;\
+	}\
+}
+
 /*
  * All partially free slob pages go on these lists.
  */
@@ -102,6 +120,12 @@
 static LIST_HEAD(free_slob_large);
 
 /*
+ * Stats for tracking slob efficiency
+ */
+unsigned long used_pages = 0;
+unsigned long free_space;
+
+/*
  * slob_page_free: true for pages on free_slob_pages list.
  */
 static inline int slob_page_free(struct page *sp)
@@ -121,6 +145,22 @@
 	__ClearPageSlobFree(sp);
 }
 
+/*static inline void count_space(struct list_head *slob_list){
+	free_space = 0;
+	slob_list = &free_slob_small;
+	list_for_each_entry(sp, slob_list, list){
+		free_space += sp->units;
+	}
+	slob_list = &free_slob_medium;
+	list_for_each_entry(sp, slob_list, list){
+		free_space += sp->units;
+	}
+	slob_list = &free_slob_large;
+	list_for_each_entry(sp, slob_list, list){
+		free_space += sp->units;
+	}
+}*/
+
 #define SLOB_UNIT sizeof(slob_t)
 #define SLOB_UNITS(size) DIV_ROUND_UP(size, SLOB_UNIT)
 
@@ -267,8 +307,8 @@
  */
 static void *slob_alloc(size_t size, gfp_t gfp, int align, int node)
 {
-	struct page *sp;
-	struct list_head *prev;
+	struct page *sp, *best_page = NULL;
+	//struct list_head *prev; //No longer used because we don't need to save our place
 	struct list_head *slob_list;
 	slob_t *b = NULL;
 	unsigned long flags;
@@ -283,6 +323,7 @@
 	spin_lock_irqsave(&slob_lock, flags);
 	/* Iterate through each partially free page, try to find room */
 	list_for_each_entry(sp, slob_list, list) {
+		free_space += sp->units;
 #ifdef CONFIG_NUMA
 		/*
 		 * If there's a node specification, search for a partial
@@ -292,23 +333,27 @@
 			continue;
 #endif
 		/* Enough room on this page? */
-		if (sp->units < SLOB_UNITS(size))
+		if (sp->units < SLOB_UNITS(size) || (best_page != NULL && sp->units >= best_page->units))
 			continue;
 
-		/* Attempt to alloc */
-		prev = sp->list.prev;
-		b = slob_page_alloc(sp, size, align);
-		if (!b)
-			continue;
+		best_page = sp;
+		
 
+		//Should not be used as the algorithm will always search every page
 		/* Improve fragment distribution and reduce our average
 		 * search time by starting our next search here. (see
 		 * Knuth vol 1, sec 2.5, pg 449) */
-		if (prev != slob_list->prev &&
+		/*if (prev != slob_list->prev &&
 				slob_list->next != prev->next)
 			list_move_tail(slob_list, prev->next);
-		break;
+		break;*/
+	}
+	/* Attempt to alloc */
+	if(best_page){
+		b = slob_page_alloc(best_page, size, align);
 	}
+	SET_FREE_SPACE();
+
 	spin_unlock_irqrestore(&slob_lock, flags);
 
 	/* Not enough space: must allocate a new page */
@@ -326,11 +371,14 @@
 		set_slob(b, SLOB_UNITS(PAGE_SIZE), b + SLOB_UNITS(PAGE_SIZE));
 		set_slob_page_free(sp, slob_list);
 		b = slob_page_alloc(sp, size, align);
+		used_pages++;
+		SET_FREE_SPACE();
 		BUG_ON(!b);
 		spin_unlock_irqrestore(&slob_lock, flags);
 	}
 	if (unlikely((gfp & __GFP_ZERO) && b))
 		memset(b, 0, size);
+
 	return b;
 }
 
@@ -362,6 +410,7 @@
 		__ClearPageSlab(sp);
 		page_mapcount_reset(sp);
 		slob_free_pages(b, 0);
+		used_pages--;
 		return;
 	}
 
@@ -416,6 +465,7 @@
 			set_slob(prev, slob_units(prev), b);
 	}
 out:
+	SET_FREE_SPACE();
 	spin_unlock_irqrestore(&slob_lock, flags);
 }
 
@@ -643,3 +693,12 @@
 {
 	slab_state = FULL;
 }
+
+asmlinkage long sys_slob_info(void){
+	unsigned long free = free_space;
+	unsigned long total = used_pages * SLOB_UNITS(PAGE_SIZE);
+	printk("Total memory in pages = %lu\n", total);
+	printk("Total free memory = %lu\n", free);
+	printk("Percentage of unnalocated memory = %lu\n", free/(total/100));
+	return 1;
+}
\ No newline at end of file
--- orig-syscall_32.tbl	2016-11-28 12:35:58.576031000 -0800
+++ syscall_32.tbl	2016-11-28 12:33:06.397413000 -0800
@@ -359,3 +359,4 @@
 350	i386	finit_module		sys_finit_module
 351	i386	sched_setattr		sys_sched_setattr
 352	i386	sched_getattr		sys_sched_getattr
+353	i386	slob_stats		sys_slob_info
--- orig-syscalls.h	2016-11-28 12:37:28.757557000 -0800
+++ syscalls.h	2016-11-26 18:17:08.817309000 -0800
@@ -855,4 +855,5 @@
 asmlinkage long sys_kcmp(pid_t pid1, pid_t pid2, int type,
 			 unsigned long idx1, unsigned long idx2);
 asmlinkage long sys_finit_module(int fd, const char __user *uargs, int flags);
+asmlinkage long sys_slob_info(void);
 #endif
